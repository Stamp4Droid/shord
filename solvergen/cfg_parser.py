#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import re
import string
import sys
import util

""" @file
Infrastructure for producing the functions in @ref Generated from a
Context-Free Grammar.

The accepted format for the input grammar is as follows:

- Except otherwise noted, the parser is insensitive to whitespace, including
  extra blank lines.
- Comments are written using the `#` character, and extend to the end of the
  line.
- A @Symbol can be any alphanumeric string (including underscores). The first
  character must be a letter. @Symbol%s are case-sensitive.
- @Symbol%s don't need to be declared before use.
- Terminal symbols are represented by strings starting with a lowercase
  character. Conversely, names for non-terminals start with an uppercase
  character.
- Each non-terminal may have one or more productions associated with it. A
  production is any sequence of @Symbol%s (terminals and/or non-terminals)
  separated by whitespace, e.g. `B c D`. Productions cannot span multiple
  lines. Empty Productions can be declared using a single `-` character.
- A special case of production is the parallel production, which is declared
  as two @Symbol%s separated by the parallel path operator, `//`, e.g.
  `A // B`. Such a production will trigger if two Edge%s, one representing
  @Symbol `A` and one representing @Symbol `B`, have the same source and target
  Node%s. Any Edge generated by such a production will also share those
  endpoints.
- A set of productions is associated with some non-terminal `A` using the
  notation `A :: ...`. The right-hand side of `::` must contain one or more
  productions (as defined above) separated by `|` marks. A series of
  productions may extend to subsequent lines, as long as each line starts a new
  production (the line must begin with `|`). A series of productions ends at
  the first blank line, or at the start of another `::` declaration (there is
  no dedicated end-of-production mark). The same non-terminal may be associated
  with any number of `::` declarations.
- Any instance of a @Symbol in a production be prefixed with `_` to signify
  that the corresponding Edge should be traversed in reverse during the
  CFL-Reachability computation.
- The Edge%s associated with a @Symbol may additionally be parameterized with
  an @Index. Instances of indexed @Symbol%s in the grammar must be suffixed by
  an index expression, `[i]`, where `i` can be any single latin letter, or the
  special character `*`. A production must contain either 0 or 2+ indexed
  symbols (including the generated @Symbol, on the LHS), and they must all use
  the same index character. The resulting code will only trigger the production
  if the indices on the Edge%s match. The special `[*]` index expression can be
  used in place of a specific @Index character on any @Symbol on the RHS, and
  will cause the generated solver code to ignore indices when matching that
  specific @Symbol. Any production can only generate a specific @Index for an
  indexed @Symbol, i.e. `[*]` cannot appear at the LHS of a production (this
  corresponds to "unsafe" rules in Datalog).
- Special directives can be added to the grammar. These are declared using the
  syntax `.<directive> <params> ...`, and must be placed alone in a line.
  Directives break preceding productions. The following directives are
  recognized:
  - `.paths <symbol> <num-paths>`: Instructs the generated solver to print out
    the selected number of witness paths for each of the Edge%s of the
    selected non-terminal @Symbol in the final graph.
  - `.lazy <symbol>`: Instructs the generated solver to avoid pre-computing the
    Edge%s for the selected non-terminal @Symbol, and instead calculate them on
    demand. Currently only supported for non-terminals appearing solely on the
    right side of parallel @Production%s, and generated directly from
    terminals.

Example of a valid grammar specification:

    S :: - | koo # this is a comment
       | A[j] _A[j] | t[f] // _s[f]
    A[i] :: foo[i] S _S bar[*]
"""

class SymbolStore(util.FinalAttrs):
    """
    A container for @Symbol%s encountered in the input grammar.
    """

    def __init__(self):
        self._num_temps = 0
        self._num_symbols = 0
        self._symbol_list = []
        self._symbol_dict = {}

    def __make_symbol(self, name, parametric):
        symbol = Symbol(name, self._num_symbols, parametric)
        self._num_symbols += 1
        self._symbol_list.append(symbol)
        self._symbol_dict[name] = symbol
        return symbol

    def find_symbol(self, name):
        """
        Return the @Symbol with the specified @a name, if it exists, otherwise
        return @e None.
        """
        return self._symbol_dict.get(name)

    def get_symbol(self, name, parametric):
        """
        Return the @Symbol with the specified @a name and properties. Create
        the @Symbol if it doesn't already exist.
        """
        symbol = self.find_symbol(name)
        if symbol is not None:
            assert symbol.parametric == parametric, \
                "Symbol %s encountered both with and without " % name + \
                "index expression"
        else:
            assert SymbolStore.valid_user_name(name), \
                "Invalid user-defined symbol: %s" % name
            symbol = self.__make_symbol(name, parametric)
        return symbol

    def make_temporary(self, parametric):
        """
        Generate a unique non-terminal @Symbol, guaranteed to never clash with
        any user-defined @Symbol.
        """
        temp_name = '%' + str(self._num_temps)
        self._num_temps += 1
        return self.__make_symbol(temp_name, parametric)

    def __iter__(self):
        """
        Iterate over all @Symbol%s encountered so far, sorted by their @Kind.
        """
        for s in self._symbol_list:
            yield s

    def kind2symbol(self, kind):
        """
        Get the @Symbol corresponding to some @Kind.
        """
        return self._symbol_list[kind]

    def num_symbols(self):
        """
        Get the number of distinct @Symbol%s encountered so far.
        """
        return self._num_symbols

    @staticmethod
    def valid_user_name(name):
        """
        Check if @a name is a valid name for a user-defined @Symbol.
        """
        return re.match(r'^[a-zA-Z]\w*$', name) is not None

class Symbol(util.FinalAttrs):
    """
    A symbol in the input grammar.
    """

    def __init__(self, name, kind, parametric):
        """
        Do not call this function directly; use
        cfg_parser::SymbolStore::get_symbol() instead.
        """
        ## The @Symbol<!-- -->'s string in the input grammar.
        self.name = name
        ## A unique number associated with this @Symbol.
        self.kind = kind
        ## Whether Edge%s of this @Symbol are parameterized by @Indices.
        self.parametric = parametric
        self.min_length = None
        self._lazy = False
        self._num_paths = 0
        self._mutables = ['min_length']

    def is_terminal(self):
        """
        Check if this is a terminal symbol of the input grammar.

        Terminal @Symbol names start with lowercase characters.
        """
        return self.name[0] in string.ascii_lowercase

    def is_lazy(self):
        """
        Check whether Edge%s for this @Symbol are calculated lazily.
        """
        return self._lazy

    def make_lazy(self):
        """
        Require that Edge%s for this @Symbol be calculated lazily.
        """
        assert not self.is_terminal()
        self._lazy = True

    def num_paths(self):
        """
        Return the number of paths we wish the solver to print for each Edge of
        this @Symbol.
        """
        return self._num_paths

    def set_num_paths(self, num_paths):
        """
        Set the number of paths we wish the solver to print for each Edge of
        this @Symbol.
        """
        assert not self.is_terminal(), \
            "Paths can only be printed for non-terminals"
        self._num_paths = num_paths

    def __key__(self):
        return self.kind

    def __eq__(self, other):
        return type(other) == Symbol and self.__key__() == other.__key__()

    def __hash__(self):
        return hash(self.__key__())

    def __str__(self):
        return self.name

    def as_lhs(self):
        """
        Print this @Symbol as it should appear on the LHS of the string
        representation of a production.
        """
        return self.name + ('[i]' if self.parametric else '')

class Literal(util.FinalAttrs):
    """
    An instance of some @Symbol in the RHS of a production.

    May optionally contain a 'reverse' modifier and/or an @Index expression.
    """

    def __init__(self, symbol, indexed, reversed=False):
        ## The @Symbol represented by this @Literal.
        self.symbol = symbol
        ## Whether this @Literal contains an @Index expression.
        #
        #  Parametric @Symbol%s with a `[*]` index expression are considered to
        #  be non-indexed.
        #
        #  We don't have to store the actual index character, since all the
        #  indexed @Literal%s in the same production must use the same
        #  character anyway.
        self.indexed = indexed
        assert not indexed or symbol.parametric, \
            "Index modifier on non-parametric symbol %s" % symbol
        ## Whether this @Literal has a 'reverse' modifier.
        self.reversed = reversed

    def __str__(self):
        return (('_' if self.reversed else '') + str(self.symbol) +
                ('' if not self.symbol.parametric else
                 '[i]' if self.indexed else '[*]'))

class RegularProduction(util.FinalAttrs):
    """
    A regular (non-parallel) production of the input @Grammar.
    """

    def __init__(self, result, used):
        RegularProduction._check_production(result, used)
        ## The @Symbol on the LHS of this @RegularProduction.
        self.result = result
        ## An ordered list of the @Literal%s on the RHS of this
        #  @RegularProduction.
        self.used = used

    def split(self, store):
        """
        Split this @RegularProduction into a list of @NormalProduction%s.

        Our splitting strategy works as follows:

            S :: a b c d e =>
            S :: ((((a b) c) d) e) =>
            T0 :: a b
            T1 :: T0 c
            T2 :: T1 d
            S  :: T2 e

        The extra @a store parameter is a @SymbolStore that will be used to
        generate any necessary temporary @Symbol%s.
        """
        num_used = len(self.used)
        if num_used == 0:
            return [NormalProduction(self.result, None, None)]
        elif num_used == 1:
            return [NormalProduction(self.result, self.used[0], None)]
        elif num_used == 2:
            return [NormalProduction(self.result, self.used[0], self.used[1])]
        r_used = self.used[1:]
        num_temps = len(self.used) - 2
        temp_parametric = [True for _ in range(0, num_temps)]
        # The only intermediate symbols that need to be indexed are those
        # between the first and the last indexed literals in the original
        # production (the result of the production counts as the rightmost
        # literal for this purpose).
        if not self.result.parametric:
            for i in range(num_temps-1, -1, -1):
                if r_used[i+1].indexed:
                    break
                else:
                    temp_parametric[i] = False
        if not self.used[0].indexed:
            for i in range(0, num_temps):
                if r_used[i].indexed:
                    break
                else:
                    temp_parametric[i] = False
        temp_symbols = [store.make_temporary(p) for p in temp_parametric]
        temp_literals = [Literal(s, s.parametric) for s in temp_symbols]
        l_used = [self.used[0]] + temp_literals
        results = temp_symbols + [self.result]
        return [NormalProduction(r, ls, rs)
                for (r, ls, rs) in zip(results, l_used, r_used)]

    @staticmethod
    def _check_production(result, used):
        """
        Test that a production of @Literal @a result using the sequence of
        @Literal%s in @a used is valid.
        """
        assert not result.is_terminal(), "Can't produce non-terminals"
        indexed_elements = ([result] if result.parametric else []) + \
            [s for s in used if s.indexed]
        assert indexed_elements == [] or len(indexed_elements) >= 2, \
            "At least two indexed elements required per production"

class NormalProduction(util.FinalAttrs):
    """
    A normalized (regular or parallel) production, with up to 2 @Literal%s on
    the RHS.
    """

    def __init__(self, result, left, right, parallel=False):
        assert not(left is None and right is not None)
        assert not(right is None and parallel)
        used = (([] if left is None else [left]) +
                ([] if right is None else [right]))
        RegularProduction._check_production(result, used)
        ## The @Symbol on the LHS of this @NormalProduction.
        self.result = result
        ## The first of up to 2 @Literal%s on the RHS. Is @e None for empty
        #  @NormalProduction%s.
        self.left = left
        ## The second of up to 2 @Literal%s on the RHS. Is @e None for empty
        #  or single @NormalProduction%s.
        self.right = right
        ## Whether this is a parallel production rather than a regular one.
        self.parallel = parallel

    def _update_result_min_length(self):
        """
        Propagate the minimum length estimates from the @Symbol%s on the RHS
        to the @Symbol on the LHS. To be used by
        cfg_parser::Grammar::calc_min_lengths().

        @return Whether this call updated the estimate for the result @Symbol.
        """
        # The length of any supporting (parallel) paths is ignored.
        left_len = 0 if self.left is None else self.left.symbol.min_length
        right_len = (0 if self.right is None or self.parallel
                     else self.right.symbol.min_length)
        newlen = left_len + right_len
        if newlen < self.result.min_length:
            self.result.min_length = newlen
            return True
        else:
            return False

    def get_rev_prods(self):
        """
        Get all the @ReverseProduction%s corresponding to this
        @NormalProduction.
        """
        if self.left is None:
            return [ReverseProduction(self.result, None)]
        elif self.right is None:
            return [ReverseProduction(self.result, self.left)]
        else:
            lpos = Position.PARALLEL_MAIN if self.parallel else Position.FIRST
            rpos = (Position.PARALLEL_SUPPORT if self.parallel
                    else Position.SECOND)
            rev_l = ReverseProduction(self.result, self.left, self.right, lpos)
            rev_r = ReverseProduction(self.result, self.right, self.left, rpos)
            return [rev_l, rev_r]

    def only_terminals(self):
        return ((self.left is None or self.left.symbol.is_terminal()) and
                (self.right is None or self.right.symbol.is_terminal()))

    def outer_search_direction(self):
        assert self.left is not None
        if self.right is None or self.parallel:
            return 'out'
        return 'in' if self.left.reversed else 'out'

    def outer_search_source(self):
        assert self.left is not None
        if self.right is None or self.parallel:
            return 'to' if self.left.reversed else 'from'
        return 'from'

    def outer_search_target(self):
        assert self.left is not None
        if self.right is None or self.parallel:
            return 'from' if self.left.reversed else 'to'
        return None

    def outer_condition(self, emit_derivs):
        assert self.left is not None
        if emit_derivs and self.left.indexed and self.result.parametric:
            return 'l->index == e->index'
        return None

    def inner_search_source(self):
        assert (self.left is not None and self.right is not None
                and not self.parallel)
        if self.right.reversed:
            return 'to'
        elif self.left.reversed:
            return 'l->from'
        else:
            return 'l->to'

    def inner_search_target(self):
        assert (self.left is not None and self.right is not None
                and not self.parallel)
        if not self.right.reversed:
            return 'to'
        elif self.left.reversed:
            return 'l->from'
        else:
            return 'l->to'

    def inner_condition(self, emit_derivs):
        assert (self.left is not None and self.right is not None
                and not self.parallel)
        if not self.right.indexed:
            return None
        elif self.left.indexed:
            return 'l->index == r->index'
        assert self.result.parametric
        if emit_derivs:
            return 'r->index == e->index'
        else:
            return None

    def result_index(self):
        if not self.result.parametric:
            return 'INDEX_NONE'
        assert self.left is not None
        if self.right is None:
            assert self.left.indexed
            return 'l->index'
        elif self.left.indexed:
            return 'l->index'
        else:
            assert self.right.indexed
            return 'r->index'

    def __str__(self):
        conj = ' // ' if self.parallel else ' '
        rhs = ('-' if self.left is None
               else str(self.left) if self.right is None
               else str(self.left) + conj + str(self.right))
        return self.result.as_lhs() + ' :: ' + rhs

class Position(util.FinalAttrs):
    """
    An enumeration of relative Edge positions in a @NormalProduction.
    """

    ## The first in a series of two Edge%s being combined through a
    #  @NormalProduction.
    FIRST = 0
    ## The second in a series of two Edge%s being combined through a
    #  @NormalProduction.
    SECOND = 1
    ## The main Edge in a pair of parallel Edge%s being combined through a
    #  @NormalProduction.
    PARALLEL_MAIN = 2
    ## The secondary (supporting) Edge in a pair of parallel Edge%s being
    #  combined through a @NormalProduction.
    PARALLEL_SUPPORT = 3

    @staticmethod
    def valid_position(pos):
        """
        Check whether @a pos is within the bounds of this enumeration.
        """
        return pos >= Position.FIRST and pos <= Position.PARALLEL_SUPPORT

class ReverseProduction(util.FinalAttrs):
    """
    A production as seen from the point of view of some element on the RHS.

    A regular production (e.g. `S :: T R`) specifies what we can combine (a
    `T` followed by an `R`) to synthesize the LHS (an `S`). Conversely, a
    @ReverseProduction (e.g. `T + (* R) => S`) assumes we already have the
    'base' (a `T`), and specifies what additional elements are required (a
    subsequent `R`) to produce the 'result' (an `S`).

    This implementation allows up to one additional required @Literal.

    The public API exposed by this class translates the abstract, grammar-level
    relations between @Symbol%s to the corresponding low-level solver
    instructions that implement those relations. In the context of the solver,
    each @Literal is represented by an Edge of the appropriate @Kind, and the
    'base' @Literal corresponds to an Edge of the appropriate @Kind which we
    are currently processing.

    We will use the @ReverseProduction `B[i] + (A[i] *) => C[i]` as a running
    example to illustrate the functionality of the methods in this class. As
    part of this example, we assume we are currently processing an Edge
    compatible with the 'base' of this @ReverseProduction, i.e., an Edge for
    @Symbol `B`.
    """

    def __init__(self, result, base, reqd=None, base_pos=Position.FIRST):
        assert not(base is None and reqd is not None), \
            "Empty productions can't take a required literal"
        assert not(reqd is None and base_pos != Position.FIRST)
        assert Position.valid_position(base_pos)
        used = (([] if base is None else [base]) +
                ([] if reqd is None else [reqd]))
        RegularProduction._check_production(result, used)
        ## The @Symbol generated by this @ReverseProduction.
        self.result = result
        ## The @Literal we assume to be present.
        #
        #  Is @e None if this corresponds to an empty production.
        self.base = base
        ## The additional @Literal we need to complete the production.
        #
        #  Is @e None if this corresponds to a single-element production.
        self.reqd = reqd
        ## What position the base @Literal has in the corresponding
        #  @NormalProduction.
        self.base_pos = base_pos

    def __check_need_to_search(self):
        assert self.base is not None, \
            "No need to search for empty productions"
        assert self.reqd is not None, \
            "No need to search for single-element productions"

    # TODO: The following methods return strings, which are tied to a
    #       particular variable and function naming. It might be more robust to
    #       return True/False and have the caller pick the strings to use.

    def search_source_endp(self):
        """
        On which endpoint of the Edge being processed we should search for an
        Edge that can complete this @ReverseProduction.

        In our running example, we need to search on the source Node.
        """
        self.__check_need_to_search()
        if self.base_pos == Position.FIRST:
            return 'from' if self.base.reversed else 'to'
        elif self.base_pos == Position.SECOND:
            return 'to' if self.base.reversed else 'from'
        elif self.base_pos == Position.PARALLEL_MAIN:
            return 'to' if self.base.reversed ^ self.reqd.reversed else 'from'
        elif self.base_pos == Position.PARALLEL_SUPPORT:
            return 'to' if self.base.reversed ^ self.reqd.reversed else 'from'
        else:
            assert False

    def search_direction(self):
        """
        On which set of Edge%s (incoming or outgoing) of the
        @link ReverseProduction::search_source_endp() search endpoint@endlink
        we should search for an Edge that can complete this @ReverseProduction.

        In our running example, we need to search within the incoming Edge%s.
        """
        self.__check_need_to_search()
        if self.base_pos == Position.FIRST:
            return 'in' if self.reqd.reversed else 'out'
        elif self.base_pos == Position.SECOND:
            return 'out' if self.reqd.reversed else 'in'
        elif self.base_pos == Position.PARALLEL_MAIN:
            return 'out'
        elif self.base_pos == Position.PARALLEL_SUPPORT:
            return 'out'
        else:
            assert False

    def search_target_endp(self):
        """
        On which endpoint (if any) of the Edge being processed we should
        constrain our search for an Edge that can complete this
        @ReverseProduction.

        In our running example, there is no such endpoint we can constrain our
        search to
        """
        self.__check_need_to_search()
        if self.base_pos == Position.FIRST:
            return None
        elif self.base_pos == Position.SECOND:
            return None
        elif self.base_pos == Position.PARALLEL_MAIN:
            return 'from' if self.base.reversed ^ self.reqd.reversed else 'to'
        elif self.base_pos == Position.PARALLEL_SUPPORT:
            return 'from' if self.base.reversed ^ self.reqd.reversed else 'to'
        else:
            assert False

    def result_source(self):
        """
        Where we should place the source Node of any Edge produced by this
        @ReverseProduction.

        In our running example, we would place it on the source Node of the
        'other' Edge (the one representing @Symbol `A`).
        """
        if self.base is None:
            edge = 'base'
            endpoint = 'from'
        elif self.reqd is None:
            edge = 'base'
            endpoint = 'to' if self.base.reversed else 'from'
        elif self.base_pos == Position.FIRST:
            edge = 'base'
            endpoint = 'to' if self.base.reversed else 'from'
        elif self.base_pos == Position.SECOND:
            edge = 'other'
            endpoint = 'to' if self.reqd.reversed else 'from'
        elif self.base_pos == Position.PARALLEL_MAIN:
            edge = 'base'
            endpoint = 'to' if self.base.reversed else 'from'
        elif self.base_pos == Position.PARALLEL_SUPPORT:
            edge = 'base'
            endpoint = 'to' if self.base.reversed else 'from'
        else:
            assert False
        return edge + '->' + endpoint

    def result_target(self):
        """
        Where we should place the target Node of any Edge produced by this
        @ReverseProduction.

        In our running example, we would place it on the target Node of the
        'base' Edge (the one representing @Symbol `B`).
        """
        if self.base is None:
            edge = 'base'
            endpoint = 'to'
        elif self.reqd is None:
            edge = 'base'
            endpoint = 'from' if self.base.reversed else 'to'
        elif self.base_pos == Position.FIRST:
            edge = 'other'
            endpoint = 'from' if self.reqd.reversed else 'to'
        elif self.base_pos == Position.SECOND:
            edge = 'base'
            endpoint = 'from' if self.base.reversed else 'to'
        elif self.base_pos == Position.PARALLEL_MAIN:
            edge = 'base'
            endpoint = 'from' if self.base.reversed else 'to'
        elif self.base_pos == Position.PARALLEL_SUPPORT:
            edge = 'base'
            endpoint = 'from' if self.base.reversed else 'to'
        else:
            assert False
        return edge + '->' + endpoint

    def result_index_source(self):
        """
        Whose @Index we should set on any Edge produced by this
        @ReverseProduction.

        In our running example, the @Indices on the combined Edge%s must match,
        so we can copy from either one of them. We arbitrarily choose to copy
        from the base Edge.
        """
        assert self.result.parametric
        if self.reqd is None:
            assert self.base.indexed
            return 'base'
        else:
            base_idx = self.base.indexed
            reqd_idx = self.reqd.indexed
            if not base_idx and reqd_idx:
                return 'other'
            elif base_idx and not reqd_idx:
                return 'base'
            elif base_idx and reqd_idx:
                return 'base'
            else:
                assert False

    def must_check_for_common_index(self):
        """
        Whether we need to add an additional @Index compatibility check for the
        two combined Edge%s.

        In our running example, we do.
        """
        return (self.base.indexed and self.reqd.indexed)

    def left_edge(self):
        if self.base is None:
            return 'NULL'
        elif self.reqd is None:
            return 'base'
        elif self.base_pos == Position.FIRST:
            return 'base'
        elif self.base_pos == Position.SECOND:
            return 'other'
        elif self.base_pos == Position.PARALLEL_MAIN:
            return 'base'
        elif self.base_pos == Position.PARALLEL_SUPPORT:
            return 'other'
        else:
            assert False

    def left_reverse(self):
        if self.base is None:
            return False
        elif self.reqd is None:
            return self.base.reversed
        elif self.base_pos == Position.FIRST:
            return self.base.reversed
        elif self.base_pos == Position.SECOND:
            return self.reqd.reversed
        elif self.base_pos == Position.PARALLEL_MAIN:
            return self.base.reversed
        elif self.base_pos == Position.PARALLEL_SUPPORT:
            return self.reqd.reversed
        else:
            assert False

    def right_edge(self):
        if self.base is None:
            return 'NULL'
        elif self.reqd is None:
            return 'NULL'
        elif self.base_pos == Position.FIRST:
            return 'other'
        elif self.base_pos == Position.SECOND:
            return 'base'
        elif self.base_pos == Position.PARALLEL_MAIN:
            return 'NULL'
        elif self.base_pos == Position.PARALLEL_SUPPORT:
            return 'NULL'
        else:
            assert False

    def right_reverse(self):
        if self.base is None:
            return False
        elif self.reqd is None:
            return False
        elif self.base_pos == Position.FIRST:
            return self.reqd.reversed
        elif self.base_pos == Position.SECOND:
            return self.base.reversed
        elif self.base_pos == Position.PARALLEL_MAIN:
            return False
        elif self.base_pos == Position.PARALLEL_SUPPORT:
            return False
        else:
            assert False

    def __str__(self):
        have = '-' if self.base is None else str(self.base)
        if self.reqd is None:
            need = ''
        elif self.base_pos == Position.FIRST:
            need = ' + (* %s)' % self.reqd
        elif self.base_pos == Position.SECOND:
            need = ' + (%s *)' % self.reqd
        elif self.base_pos == Position.PARALLEL_MAIN:
            need = ' + (* // %s)' % self.reqd
        elif self.base_pos == Position.PARALLEL_SUPPORT:
            need = ' + (%s // *)' % self.reqd
        else:
            assert False
        return have + need + ' => ' + self.result.as_lhs()

class Grammar(util.FinalAttrs):
    """
    A representation of the input grammar. Can be built incrementally by
    feeding it a text representation of a grammar line-by-line.
    """

    def __init__(self):
        self._lhs = None
        self._lhs_index_char = None
        ## All the @Symbol%s encountered so far, stored in a specialized
        #  @SymbolStore container.
        self.symbols = SymbolStore()
        ## All the @NormalProduction%s encountered so far, grouped by result
        #  @Symbol.
        self.prods = util.OrderedMultiDict()
        ## All the @ReverseProduction%s encountered so far, grouped by base
        #  @Symbol.
        self.rev_prods = util.OrderedMultiDict()

    def finalize(self):
        """
        Run final sanity checks and calculations, which require all
        @Production%s to be present.
        """
        for s in self.symbols:
            if not s.is_terminal() and self.prods.get(s) == []:
                assert False, "Non-terminal %s can never be produced" % s
            if s.is_lazy():
                for rp in self.rev_prods.get(s):
                    assert rp.base_pos == Position.PARALLEL_SUPPORT, \
                        "Lazy symbol %s appears in disallowed position" % s
                for p in self.prods.get(s):
                    assert p.only_terminals(), \
                        "Lazy symbol %s constructed from non-terminals" % s
                    assert not p.parallel, \
                        "Lazy symbol %s constructed from parallel rule" % s
                assert s.num_paths() == 0, \
                        "Can't print paths for lazy symbol %s " % s
        self._calc_min_lengths()
        # TODO: Also disable parse_line().

    def _calc_min_lengths(self):
        for symbol in self.symbols:
            # TODO: Arbitrary value for "infinite length"
            symbol.min_length = 1 if symbol.is_terminal() else 10000
        fixpoint = False
        while not fixpoint:
            fixpoint = True
            for symbol in self.prods:
                for p in self.prods.get(symbol):
                    if p._update_result_min_length():
                        fixpoint = False

    def parse_line(self, line):
        """
        Parse the next line of the grammar specification.
        """
        line_wo_comment = (line.split('#'))[0]
        toks = line_wo_comment.split()
        if toks == [] or toks[0].startswith("."):
            # This is a special, non-production line, so we interrupt any
            # ongoing productions.
            self._lhs = None
            self._lhs_index_char = None
            if toks != []:
                self.__parse_directive(toks[0][1:], toks[1:])
            return
        # This line contains one or more production definitions.
        if toks[0] == '|':
            # This line continues a series of productions.
            assert self._lhs is not None, "| without preceding production"
            toks = toks[1:]
        elif len(toks) >= 2 and toks[1] == '::':
            # This line starts a new production.
            (self._lhs, self._lhs_index_char) = self.__parse_lhs(toks[0])
            toks = toks[2:]
        else:
            assert False, "Malformed production"
        while '|' in toks:
            split_pos = toks.index('|')
            self.__parse_production(toks[:split_pos])
            toks = toks[split_pos+1:]
        self.__parse_production(toks)

    def __parse_directive(self, directive, params):
        if directive == 'paths' and len(params) == 2:
            symbol = self.symbols.find_symbol(params[0])
            assert symbol is not None, \
                "Symbol %s not declared (yet)" % params[0]
            symbol.set_num_paths(int(params[1]))
        elif directive == 'lazy' and len(params) == 1:
            symbol = self.symbols.find_symbol(params[0])
            assert symbol is not None, \
                "Symbol %s not declared (yet)" % params[0]
            symbol.make_lazy()
        else:
            assert False, "Unknown directive: %s/%s" % (directive, len(params))

    def __parse_production(self, toks):
        assert toks != [], "Empty production not marked with '-'"
        used = []
        indices = []
        parallel = False
        if toks != ['-']:
            if len(toks) == 3 and toks[1] == '//':
                parallel = True
                toks = [toks[0], toks[2]]
            indices.append(self._lhs_index_char)
            for t in toks:
                (lit, i) = self.__parse_literal(t)
                used.append(lit)
                indices.append(i)
        assert util.all_same([i for i in indices if i is not None]), \
            "Production contains more than one distinct indices"
        if parallel:
            assert len(used) == 2
            prods = [NormalProduction(self._lhs, used[0], used[1], True)]
        else:
            prods = RegularProduction(self._lhs, used).split(self.symbols)
        for p in prods:
            self.prods.append(p.result, p)
            for rp in p.get_rev_prods():
                base_symbol = None if rp.base is None else rp.base.symbol
                self.rev_prods.append(base_symbol, rp)

    def __parse_literal(self, str):
        matcher = re.match(r'^(_?)([a-zA-Z]\w*)(?:\[([a-zA-Z\*])\])?$', str)
        assert matcher is not None, "Malformed literal: %s" % str
        reversed = matcher.group(1) != ''
        index_char = matcher.group(3)
        symbol = self.symbols.get_symbol(matcher.group(2),
                                         index_char is not None)
        if index_char == '*':
            index_char = None
        indexed = index_char is not None
        return (Literal(symbol, indexed, reversed), index_char)

    def __parse_lhs(self, str):
        matcher = re.match(r'^([a-zA-Z]\w*)(?:\[([a-zA-Z])\])?$', str)
        assert matcher is not None, "Malformed production LHS: %s" % str
        index_char = matcher.group(2)
        symbol = self.symbols.get_symbol(matcher.group(1),
                                         index_char is not None)
        return (symbol, index_char)

def parse(grammar_in, code_out, terminals_out):
    """
    Read a grammar specification and generate the corresponding solver code.

    @param [in] grammar_in A File-like object to read the @Grammar from.
    @param [out] code_out A File-like object to write the generated code to.
    @param [out] terminals_out If this File-like object is not @e None, use it
           to print out a list of the terminal @Symbol%s in the input @Grammar.
    """
    grammar = Grammar()
    pr = util.CodePrinter(code_out)

    pr.write('#include <assert.h>')
    pr.write('#include <list>')
    pr.write('#include <stdbool.h>')
    pr.write('#include <string.h>')
    pr.write('#include "solvergen.hpp"')
    pr.write('')

    pr.write('/* Original Grammar:')
    for line in grammar_in:
        grammar.parse_line(line)
        pr.write(line, False)
    grammar.finalize()
    pr.write('*/')
    pr.write('')

    pr.write('/* Normalized Grammar:')
    pr.write('%s' % grammar.prods)
    pr.write('*/')
    pr.write('')

    pr.write('/* Reverse Productions:')
    pr.write('%s' % grammar.rev_prods)
    pr.write('*/')
    pr.write('')

    pr.write('PATH_LENGTH static_min_length(EDGE_KIND kind) {')
    pr.write('switch (kind) {')
    for s in grammar.symbols:
        pr.write('case %s: return %s; /* %s */' % (s.kind, s.min_length, s))
    pr.write('default: assert(false);')
    pr.write('}')
    pr.write('}')
    pr.write('')

    pr.write('bool is_terminal(EDGE_KIND kind) {')
    pr.write('switch (kind) {')
    for s in grammar.symbols:
        if s.is_terminal():
            pr.write('case %s: return true; /* %s */' % (s.kind, s))
    pr.write('default: return false;')
    pr.write('}')
    pr.write('}')
    pr.write('')

    pr.write('bool is_parametric(EDGE_KIND kind) {')
    pr.write('switch (kind) {')
    for s in grammar.symbols:
        if s.parametric:
            pr.write('case %s: return true; /* %s */' % (s.kind, s))
    pr.write('default: return false;')
    pr.write('}')
    pr.write('}')
    pr.write('')

    pr.write('bool has_empty_prod(EDGE_KIND kind) {')
    empty_prod_symbols = [r.result for r in grammar.rev_prods.get(None)]
    pr.write('switch (kind) {')
    if empty_prod_symbols != []:
        for s in empty_prod_symbols:
            pr.write('case %s: /* %s */' % (s.kind, s))
        pr.write('return true;')
    pr.write('default:')
    pr.write('return false;')
    pr.write('}')
    pr.write('}')
    pr.write('')

    pr.write('EDGE_KIND num_kinds() {')
    pr.write('return %s;' % grammar.symbols.num_symbols())
    pr.write('}')
    pr.write('')

    pr.write('EDGE_KIND symbol2kind(const char *symbol) {')
    for s in grammar.symbols:
        pr.write('if (strcmp(symbol, "%s") == 0) return %s;' % (s, s.kind))
    pr.write('assert(false);')
    pr.write('}')
    pr.write('')

    pr.write('const char *kind2symbol(EDGE_KIND kind) {')
    pr.write('switch (kind) {')
    for s in grammar.symbols:
        pr.write('case %s: return "%s";' % (s.kind, s))
    pr.write('default: assert(false);')
    pr.write('}')
    pr.write('}')
    pr.write('')

    pr.write('unsigned int num_paths_to_print(EDGE_KIND kind) {')
    pr.write('switch (kind) {')
    for s in grammar.symbols:
        if s.num_paths() > 0:
            pr.write('case %s: return %s; /* %s */'
                     % (s.kind, s.num_paths(), s))
    pr.write('default: return 0;')
    pr.write('}')
    pr.write('}')
    pr.write('')

    pr.write('bool is_lazy(EDGE_KIND kind) {')
    pr.write('switch (kind) {')
    for s in grammar.symbols:
        if s.is_lazy():
            pr.write('case %s: return true; /* %s */' % (s.kind, s))
    pr.write('default: return false;')
    pr.write('}')
    pr.write('}')
    pr.write('')

    pr.write('void main_loop(Edge *base) {')
    pr.write('Edge *other;')
    # TODO: Local iterator variables may go unused: use per-case variables,
    # enclosed in {} blocks.
    pr.write('OutEdgeIterator *out_iter;')
    pr.write('LazyOutEdgeIterator *lazy_out_iter;')
    pr.write('InEdgeIterator *in_iter;')
    # TODO: Could cache base->index
    pr.write('switch (base->kind) {')
    for base_symbol in grammar.symbols:
        rev_prods = grammar.rev_prods.get(base_symbol)
        if rev_prods == []:
            # This symbol doesn't appear on the RHS of any production.
            continue
        pr.write('case %s: /* %s */' % (base_symbol.kind, base_symbol))
        if base_symbol.is_lazy():
            # Lazy edges should never get produced, and thus never enter the
            # worklist.
            pr.write('assert(false);')
            continue
        for rp in rev_prods:
            if rp.result.is_lazy():
                # Skip productions that generate lazy symbols.
                continue
            pr.write('/* %s */' % rp)
            res_src = rp.result_source()
            res_tgt = rp.result_target()
            res_kind = rp.result.kind
            l_edge = rp.left_edge()
            l_rev = util.to_c_bool(rp.left_reverse())
            r_edge = rp.right_edge()
            r_rev = util.to_c_bool(rp.right_reverse())
            res_idx = ('%s->index' % rp.result_index_source()
                       if rp.result.parametric else 'INDEX_NONE')
            # TODO: We don't have to worry about what information to record for
            # lazy constituent edges, because those edges are only allowed on
            # the supporting position of parallel productions, where producing
            # edges are not recorded anyway.
            add_edge_stmt = ('add_edge(%s, %s, %s, %s, %s, %s, %s, %s);'
                             % (res_src, res_tgt, res_kind, res_idx,
                                l_edge, l_rev, r_edge, r_rev))
            if rp.reqd is None:
                pr.write(add_edge_stmt)
            else:
                lazy_mod = 'lazy_' if rp.reqd.symbol.is_lazy() else ''
                search_src = 'base->' + rp.search_source_endp()
                search_dir = rp.search_direction()
                search_tgt_endp = rp.search_target_endp()
                search_tgt = (None if search_tgt_endp is None
                              else 'base->' + search_tgt_endp)
                reqd_kind = rp.reqd.symbol.kind
                pr.write('%s%s_iter = get_%s%s_edge_iterator%s(%s%s, %s);'
                         % (lazy_mod, search_dir, lazy_mod, search_dir,
                            '' if search_tgt is None else '_to_target',
                            search_src,
                            '' if search_tgt is None else (', ' + search_tgt),
                            reqd_kind))
                pr.write('while ((other = next_%s%s_edge(%s%s_iter)) != NULL) {'
                         % (lazy_mod, search_dir, lazy_mod, search_dir))
                if rp.must_check_for_common_index():
                    pr.write('if (base->index == other->index) {')
                    pr.write(add_edge_stmt)
                    pr.write('}')
                else:
                    pr.write(add_edge_stmt)
                pr.write('}')
        pr.write('break;')
    pr.write('}')
    pr.write('}')
    pr.write('')

    emit_derivs_or_lazy_edges(grammar, pr, True)

    emit_derivs_or_lazy_edges(grammar, pr, False)

    if terminals_out is not None:
        for s in grammar.symbols:
            if s.is_terminal():
                terminals_out.write('%s\n' % s)

def emit_derivs_or_lazy_edges(grammar, pr, emit_derivs):
    if emit_derivs:
        pr.write('std::list<Derivation> all_derivations(Edge *e) {')
        pr.write('std::list<Derivation> derivs;')
        pr.write('NODE_REF from = e->from;')
        pr.write('NODE_REF to = e->to;')
        pr.write('EDGE_KIND kind = e->kind;')
    else:
        pr.write('std::list<Edge *> *all_lazy_edges(NODE_REF from, ' +
                 'NODE_REF to, EDGE_KIND kind) {')
        pr.write('auto edges = new std::list<Edge *>();')
    pr.write('Edge *l, *r;')
    # TODO: Local iterator variables may go unused: use per-case variables,
    # enclosed in {} blocks.
    # TODO: Lazy edges are only allowed on the supporting position of parallel
    # productions, which is not used during path reconstruction, so we don't
    # have to consider that case when emitting all_derivations.
    # TODO: Similarly, only terminals are allowed in rules producing lazy
    # edges, and terminals can't be lazy, so we don't have to consider that
    # case when emitting all_lazy_edges.
    # TODO: For lazy edge construction, if there's only one edge that could be
    # produced, we can stop the search immediatelly once we first construct it.
    # In that case, we must make sure we deallocate the iterators. With the
    # current set-up it's possible to produce multiple copies of the same Edge
    # on the output list, which can cause a blow-up in the case of nested lazy
    # edges (which we currently don't support).
    pr.write('OutEdgeIterator *l_out_iter, *r_out_iter;')
    pr.write('InEdgeIterator *l_in_iter;')
    pr.write('switch (kind) {')
    for e_symbol in grammar.prods:
        pr.write('case %s: /* %s */' % (e_symbol.kind, e_symbol))
        if e_symbol.is_lazy() ^ (not emit_derivs):
            # Derivation re-construction should never be requested for lazy
            # edges, because none are ever produced.
            # Conversely, only lazy symbols should be passed to all_lazy_edges.
            pr.write('assert(false);')
            continue
        for p in grammar.prods.get(e_symbol):
            pr.write('/* %s */' % p)
            e_idx = p.result_index()
            if p.left is None:
                # Empty production
                pr.write('if (from == to) {')
                if emit_derivs:
                    pr.write('derivs.push_back(derivation_empty());')
                else:
                    pr.write('edges->push_back(edge_new(from, to, kind, ' +
                             '%s, NULL, false, NULL, false));' % e_idx)
                pr.write('}')
                continue
            l_rev = util.to_c_bool(p.left.reversed)
            out_dir = p.outer_search_direction()
            out_src = p.outer_search_source()
            out_tgt = p.outer_search_target()
            pr.write('l_%s_iter = get_%s_edge_iterator%s(%s%s, %s);'
                     % (out_dir, out_dir,
                        '_to_target' if out_tgt is not None else '',
                        out_src,
                        (', ' + out_tgt) if out_tgt is not None else '',
                        p.left.symbol.kind))
            pr.write('while ((l = next_%s_edge(l_%s_iter)) != NULL) {'
                     % (out_dir, out_dir))
            out_cond = p.outer_condition(emit_derivs)
            if out_cond is not None:
                pr.write('if (%s) {' % out_cond)
            if p.right is None or p.parallel:
                # single or parallel production
                if emit_derivs:
                    # BUG: No index check happens for parallel rules, so for a
                    # rule like `A :: x[i] // y[i]` we may return a source edge
                    # with a wrong index. To fix this, we'd need to iterate
                    # over all possible r-edges to find a witness one, but then
                    # throw it away (this invalidates our previous hypothesis
                    # that supporting parallel edges are completely ignored
                    # during path reconstruction).
                    pr.write('derivs.push_back(derivation_single(l, %s));'
                             % l_rev)
                else:
                    # TODO: Parallel productions for lazy edges are currently
                    # unsupported.
                    assert not p.parallel
                    pr.write('edges->push_back(edge_new(from, to, kind, ' +
                             '%s, l, %s, NULL, false));' % (e_idx, l_rev))
            else:
                # double production
                r_rev = util.to_c_bool(p.right.reversed)
                pr.write('r_out_iter = get_out_edge_iterator_to_target' +
                         ('(%s, %s, %s);' % (p.inner_search_source(),
                                             p.inner_search_target(),
                                             p.right.symbol.kind)))
                pr.write('while ((r = next_out_edge(r_out_iter)) != NULL) {')
                in_cond = p.inner_condition(emit_derivs)
                if in_cond is not None:
                    pr.write('if (%s) {' % in_cond)
                if emit_derivs:
                    pr.write('derivs.push_back(derivation_double' +
                             '(l, %s, r, %s));' % (l_rev, r_rev))
                else:
                    pr.write('edges->push_back(edge_new(from, to, kind, ' +
                             '%s, l, %s, r, %s));' % (e_idx, l_rev, r_rev))
                if in_cond is not None:
                    pr.write('}')
                pr.write('}')
            if out_cond is not None:
                pr.write('}')
            pr.write('}')
        pr.write('break;')
    pr.write('default:')
    pr.write('assert(false);')
    pr.write('}')
    if emit_derivs:
        pr.write('return derivs;')
    else:
        pr.write('return edges;')
    pr.write('}')
    pr.write('')

# TODO: More user-friendly error output than assertion failure
# TODO: More structured way to synthesize code: specialized C-code synthesis
#       class, or put base program text in a large triple-quoted string and
#       leave %s's for places to fill in.

## Help message describing the calling convention for this script.
usage_string = """Usage: %s <input-file> [<output-dir> [<terminals-file>]]
Produce CFL-Reachability solver code for a Context-Free Grammar.
<input-file> must contain a grammar specification (see the main project docs
for details), and have a .cfg extension.
Output is printed to a file inside <output-dir> with the same name as
<input-file>, but with the .cfg extension stripped.
If no output directory is given, print generated code to stdout.
If <terminals-file> is specified, write a list of the terminal symbols used in
this grammar to that file.
"""

def _main():
    if (len(sys.argv) < 2 or sys.argv[1] == '-h' or sys.argv[1] == '--help' or
        os.path.splitext(sys.argv[1])[1] != '.cfg'):
        script_name = os.path.basename(__file__)
        sys.stderr.write(usage_string % script_name)
        exit(1)
    with open(sys.argv[1], 'r') as grammar_in:
        if len(sys.argv) >= 3:
            base_outfile = os.path.basename(os.path.splitext(sys.argv[1])[0])
            outfile = os.path.join(sys.argv[2], base_outfile + '.cpp')
            with open(outfile, 'w') as code_out:
                if len(sys.argv) >= 4:
                    with open(sys.argv[3], 'w') as terminals_out:
                        parse(grammar_in, code_out, terminals_out)
                else:
                    parse(grammar_in, code_out, None)
        else:
            parse(grammar_in, sys.stdout, None)

if __name__ == '__main__':
    _main()
